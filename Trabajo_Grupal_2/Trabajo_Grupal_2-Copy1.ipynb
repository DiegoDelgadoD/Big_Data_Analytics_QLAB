{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a64ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dask[complete] dask-ml pandas scikit-learn --user\n",
    "#import os \n",
    "#!pip install --upgrade numpy pandas --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b33fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DDelgado\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\DDelgado\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import dask_ml.model_selection as dml\n",
    "from dask_ml.model_selection import train_test_split\n",
    "\n",
    "import dask_ml.metrics as dmm\n",
    "from dask_ml.linear_model import LogisticRegression\n",
    "from dask.distributed import Client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4f6934",
   "metadata": {},
   "source": [
    "# Trabajo grupal 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c009417",
   "metadata": {},
   "source": [
    "## Parte I\n",
    "\n",
    "**1. Relación entre Dask y el Método de Foster**\n",
    "\n",
    "Dask, una biblioteca de Python para la computación en paralelo, se relaciona con el método de Foster al estructurar y descomponer tareas complejas en sub-tareas manejables. El método de Foster consta de varias etapas: particionamiento, comunicación, agregación y mapeo. Estas etapas encuentran un paralelo en cómo Dask maneja las tareas mediante su motor de ejecución de grafos.\n",
    " \n",
    "Por ejemplo, cuando utilizamos Dask para procesar un gran dataframe, este se divide en múltiples dataframes más pequeños (particionamiento). Luego, Dask optimiza la distribución de estas tareas a través de la red de hardware disponible, minimizando la sobrecarga de comunicación. Además, Dask ejecuta las sub-tareas de manera eficiente y paralela (agregación y mapeo). Un ejemplo práctico sería la carga y análisis de un gran conjunto de datos, donde Dask divide el dataframe y asigna cada parte a diferentes núcleos o nodos, realizando operaciones en paralelo y reuniendo los resultados finales.\n",
    "\n",
    "**2. Ineficiencias de la paralelización**\n",
    "\n",
    "La paralelización puede volverse ineficiente en ciertas circunstancias, principalmente debido a la sobrecarga de comunicación y la granularidad de las tareas. Permíteme explicarte:\n",
    "\n",
    "- **Sobrecarga de comunicación:** Cuando las tareas requieren una alta comunicación entre procesos, como en algoritmos con fuertes dependencias de datos entre los nodos, la sobrecarga de comunicación puede superar los beneficios de la paralelización. Por ejemplo, en un algoritmo de búsqueda de camino mínimo, si cada nodo debe comunicarse frecuentemente con otros, la latencia y el tiempo de transmisión de datos pueden hacer que la paralelización sea ineficiente.\n",
    "- **Granularidad de las tareas:** Si las tareas son demasiado pequeñas (granularidad fina), el tiempo dedicado a administrar las tareas y coordinar entre núcleos puede ser mayor que el tiempo de ejecución de las propias tareas. Un ejemplo ilustrativo es la paralelización de operaciones simples, como la suma de una pequeña lista de números. En este caso, el costo de distribuir las tareas y reunir los resultados puede ser mayor que simplemente realizar la operación en serie\n",
    "\n",
    "**3. Good data vs Big data**\n",
    "\n",
    "El artículo de Desouza y Smith (2014) en la Stanford Social Innovation Review resalta la promesa y los desafíos del big data para la innovación social. Por otro lado, Andrew Ng en su presentación en el Data+AI Summit 2022 destacó la importancia de los datos de calidad (\"Good Data\") para el éxito de los proyectos de inteligencia artificial. La discusión sobre si \"Good Data\" reemplazará al \"Big Data\" es crucial.\n",
    "\n",
    "¿Uno reemplazará al otro?\n",
    "\n",
    "En base al articulo y a la conferencia, podemos deducir que es poco probable que la \"Good Data\" reemplace a la \"Big Data\". Ambos conceptos abordan necesidades **distintas y complementarias**. La \"Big Data\" se refiere a la capacidad de manejar grandes volúmenes de datos variados y rápidos, esenciales para descubrir patrones y tendencias a gran escala. En contraste, \"Good Data\" enfatiza la calidad, precisión y relevancia de los datos, cruciales para la toma de decisiones informadas y la creación de modelos de IA efectivos. Una manera de resaltar el porqué no son reemplazables es colocarnos en el caso hipotético en el que tenemos un volumen de datos gigante pero que es difuso y no tiene un etiquetado correcto (no seríamos eficientes). \n",
    "\n",
    "¿Se pueden complementar y cómo?\n",
    "Sí, \"Good Data\" y \"Big Data\" pueden y deben complementarse. Lo mejor de la Big Data proporciona es **la amplitud y diversidad** necesarias para captar una visión completa de fenómenos complejos. Por otro lado, la Good Data asegura que las decisiones y modelos derivados sean **precisos y confiables**. Integrar ambos enfoques puede maximizar el valor de los datos, logrando resultados más robustos y significativos.\n",
    "\n",
    "Ejemplos en el contexto peruano:\n",
    "\n",
    "- Salud Pública: En Perú, el uso de Big Data para monitorear la propagación de enfermedades como el dengue puede ser muy efectivo. Sin embargo, la calidad de los datos recopilados es vital. Usar Good Data en la validación de fuentes y limpieza de datos asegura que las políticas de salud basadas en estos análisis sean precisas y efectivas. Por ejemplo, no nos serviría mucho tener millones de testeos de dengue con pruebas poco precisas; sería mejor optimizar los recursos y basarnos en menso pruebas que sean más precisas.\n",
    "\n",
    "- Educación: Big Data puede ayudar a identificar tendencias en el rendimiento académico a nivel nacional. Complementarlo con Good Data, recolectando información precisa y relevante sobre factores socioeconómicos y métodos de enseñanza, permite desarrollar intervenciones educativas más acertadas y personalizadas. Por ejemplo, sería ideal tener datos de las notas de todos los estudiantes del Perú; sin embargo, si no concoemos cómo se generaron estas (las evaluaciones), no tendríamos medidas precisas que reflejen el desepeño de los estudiantes.\n",
    "\n",
    "En conclusión, mientras que **Big Data proporciona la amplitud necesaria para capturar la complejidad de problemas sociales**, **Good Data garantiza que las soluciones derivadas sean precisas y efectivas**. Integrar ambos enfoques es esencial para abordar problemas complejos de manera holística y eficiente\n",
    "\n",
    "**4. Dask en contextos reales** \n",
    "\n",
    "Dask puede ser extremadamente útil para acelerar el procesamiento y análisis de registros de datos. Dask permite manejar grandes volúmenes de datos dividiéndolos en partes más pequeñas y procesándolos en paralelo, lo que es crucial para manejar eficientemente datos a gran escala.\n",
    "\n",
    "**Ejemplo:** Imaginemos que la empresa en la que trabajmos necesita analizar las ventas por región para identificar patrones de comportamiento de los clientes y optimizar las estrategias de marketing. Los datos de ventas incluyen millones de registros con información como ID de venta, fecha, región, producto, categoría , cantidad vendida y precio. Sigamos los siguientes pasos:\n",
    "\n",
    "\n",
    "1. Cargar datos en paralelo: Utilizando dask.dataframe.read_csv, se pueden cargar múltiples archivos CSV en paralelo, lo que acelera significativamente el proceso de carga comparado con pandas.\n",
    "\n",
    " ```python\n",
    "   import dask.dataframe as dd\n",
    "\n",
    "   # Cargar datos de ventas en paralelo\n",
    "   df = dd.read_csv('ruta_a_data_ventas/data.csv')\n",
    " ```   \n",
    " \n",
    "\n",
    "2. Transformación de datos: Dask permite realizar operaciones de transformación, como agrupar y sumar ventas por región, utilizando una sintaxis similar a pandas, pero ejecutándose en paralelo.\n",
    "\n",
    " ```python\n",
    "sales_by_region = df.groupby('region')['sales_amount'].sum().compute()\n",
    " ```\n",
    "\n",
    "3. Manejo de datos que no caben en memoria: Dask puede manejar datasets que no caben en la memoria dividiéndolos en partes más pequeñas y procesándolos en discos duros. Esto es especialmente útil para grandes volúmenes de datos de ventas.\n",
    "\n",
    "4. Visualización y análisis en tiempo real: Usando el dashboard de Dask, los analistas pueden monitorear el progreso del procesamiento y ajustar las tareas en tiempo real.\n",
    "\n",
    "**Ventajas de Dask:**\n",
    "\n",
    "- **Paralelización**: Dask descompone el trabajo en tareas más pequeñas que se ejecutan simultáneamente, maximizando el uso de los recursos de CPU y memoria disponibles, hacemos un uso eficiente de nuestros recursos. Esto reduce considerablemente el tiempo de procesamiento en comparación con el enfoque secuencial de pandas. Lo cual es importante en contextos donde necesitamos los datos ASAP.\n",
    "- **Escalabilidad**: Dask puede adaptarse desde una sola laptop hasta un clúster de computadoras, permitiendo manejar conjuntos de datos que van desde gigabytes hasta terabytes sin necesidad de modificar el código.\n",
    "- **Interoperabilidad**: Dask se integra de manera fluida con otras bibliotecas de Python como NumPy y pandas, permitiendo a los desarrolladores aprovechar sus herramientas y habilidades existentes sin tener que aprender una nueva sintaxis. Esto ayudaría un monton pues la curva de aprendizaje de esta sintaxis sería muy beneficiosa en comparacion a otro método.\n",
    "- **Elasticidad y tolerancia a fallos**: Dask ajusta dinámicamente la distribución de tareas según los recursos de hardware disponibles y maneja fallos en los nodos sin interrumpir el procesamiento general.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a1f31ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCDD</th>\n",
       "      <th>DEPARTAMENTO</th>\n",
       "      <th>CCPP</th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>CCDI</th>\n",
       "      <th>DISTRITO</th>\n",
       "      <th>CIUDAD</th>\n",
       "      <th>CONGLOMERADO</th>\n",
       "      <th>NSELV</th>\n",
       "      <th>VIVIENDA</th>\n",
       "      <th>...</th>\n",
       "      <th>P805_3</th>\n",
       "      <th>P805_4</th>\n",
       "      <th>P805_5</th>\n",
       "      <th>P805_6</th>\n",
       "      <th>P805_7</th>\n",
       "      <th>P805_8</th>\n",
       "      <th>P805_9</th>\n",
       "      <th>P806</th>\n",
       "      <th>P807</th>\n",
       "      <th>factorfinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ANCASH</td>\n",
       "      <td>18</td>\n",
       "      <td>SANTA</td>\n",
       "      <td>1</td>\n",
       "      <td>CHIMBOTE</td>\n",
       "      <td>Chimbote</td>\n",
       "      <td>1206802</td>\n",
       "      <td>9340</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.175820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ANCASH</td>\n",
       "      <td>18</td>\n",
       "      <td>SANTA</td>\n",
       "      <td>1</td>\n",
       "      <td>CHIMBOTE</td>\n",
       "      <td>Chimbote</td>\n",
       "      <td>1206802</td>\n",
       "      <td>9340</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13.175820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ANCASH</td>\n",
       "      <td>18</td>\n",
       "      <td>SANTA</td>\n",
       "      <td>1</td>\n",
       "      <td>CHIMBOTE</td>\n",
       "      <td>Chimbote</td>\n",
       "      <td>1206802</td>\n",
       "      <td>9340</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13.175820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>ANCASH</td>\n",
       "      <td>18</td>\n",
       "      <td>SANTA</td>\n",
       "      <td>1</td>\n",
       "      <td>CHIMBOTE</td>\n",
       "      <td>Chimbote</td>\n",
       "      <td>1206802</td>\n",
       "      <td>9340</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13.175820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>ANCASH</td>\n",
       "      <td>18</td>\n",
       "      <td>SANTA</td>\n",
       "      <td>1</td>\n",
       "      <td>CHIMBOTE</td>\n",
       "      <td>Chimbote</td>\n",
       "      <td>1206802</td>\n",
       "      <td>9340</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13.175820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12482</th>\n",
       "      <td>24</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>1</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>1</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>Tumbes</td>\n",
       "      <td>44789</td>\n",
       "      <td>396</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12.281439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12483</th>\n",
       "      <td>24</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>1</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>1</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>Tumbes</td>\n",
       "      <td>44789</td>\n",
       "      <td>397</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12.281439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12484</th>\n",
       "      <td>24</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>1</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>1</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>Tumbes</td>\n",
       "      <td>44789</td>\n",
       "      <td>397</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12.281439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12485</th>\n",
       "      <td>24</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>1</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>1</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>Tumbes</td>\n",
       "      <td>44789</td>\n",
       "      <td>397</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12.281439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12486</th>\n",
       "      <td>24</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>1</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>1</td>\n",
       "      <td>TUMBES</td>\n",
       "      <td>Tumbes</td>\n",
       "      <td>44789</td>\n",
       "      <td>397</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12.281439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12487 rows × 487 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CCDD DEPARTAMENTO  CCPP PROVINCIA  CCDI  DISTRITO    CIUDAD  \\\n",
       "0         2       ANCASH    18     SANTA     1  CHIMBOTE  Chimbote   \n",
       "1         2       ANCASH    18     SANTA     1  CHIMBOTE  Chimbote   \n",
       "2         2       ANCASH    18     SANTA     1  CHIMBOTE  Chimbote   \n",
       "3         2       ANCASH    18     SANTA     1  CHIMBOTE  Chimbote   \n",
       "4         2       ANCASH    18     SANTA     1  CHIMBOTE  Chimbote   \n",
       "...     ...          ...   ...       ...   ...       ...       ...   \n",
       "12482    24       TUMBES     1    TUMBES     1    TUMBES    Tumbes   \n",
       "12483    24       TUMBES     1    TUMBES     1    TUMBES    Tumbes   \n",
       "12484    24       TUMBES     1    TUMBES     1    TUMBES    Tumbes   \n",
       "12485    24       TUMBES     1    TUMBES     1    TUMBES    Tumbes   \n",
       "12486    24       TUMBES     1    TUMBES     1    TUMBES    Tumbes   \n",
       "\n",
       "       CONGLOMERADO  NSELV  VIVIENDA  ...  P805_3  P805_4  P805_5  P805_6  \\\n",
       "0           1206802   9340         3  ...                                   \n",
       "1           1206802   9340         3  ...                                   \n",
       "2           1206802   9340         3  ...                                   \n",
       "3           1206802   9340         3  ...                                   \n",
       "4           1206802   9340         3  ...                                   \n",
       "...             ...    ...       ...  ...     ...     ...     ...     ...   \n",
       "12482         44789    396        13  ...                                   \n",
       "12483         44789    397        14  ...                                   \n",
       "12484         44789    397        14  ...                                   \n",
       "12485         44789    397        14  ...                                   \n",
       "12486         44789    397        14  ...                                   \n",
       "\n",
       "       P805_7  P805_8  P805_9  P806  P807  factorfinal  \n",
       "0                                 1     1    13.175820  \n",
       "1                                            13.175820  \n",
       "2                                            13.175820  \n",
       "3                                            13.175820  \n",
       "4                                 1     2    13.175820  \n",
       "...       ...     ...     ...   ...   ...          ...  \n",
       "12482                             3     2    12.281439  \n",
       "12483                                        12.281439  \n",
       "12484                                        12.281439  \n",
       "12485                                        12.281439  \n",
       "12486                             3     2    12.281439  \n",
       "\n",
       "[12487 rows x 487 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar los datos con Dask\n",
    "df = pd.read_csv('..\\data\\ENPOVE2022_V_200-300-400-500-600-700-800.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba6fdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DDelgado\\anaconda3\\lib\\site-packages\\distributed\\node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 53170 instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\DDelgado\\anaconda3\\lib\\site-packages\\distributed\\client.py:3357: UserWarning: Sending large graph of size 50.42 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\DDelgado\\AppData\\Local\\Temp\\ipykernel_13868\\1084635565.py\", line 49, in <module>\n",
      "    grid_search.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\DDelgado\\AppData\\Roaming\\Python\\Python39\\site-packages\\dask_ml\\model_selection\\_search.py\", line 1272, in fit\n",
      "    for batch in ac.batches():\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\site-packages\\distributed\\client.py\", line 5967, in batches\n",
      "    yield self.next_batch(block=True)\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\site-packages\\distributed\\client.py\", line 5939, in next_batch\n",
      "    batch = [next(self)]\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\site-packages\\distributed\\client.py\", line 5895, in __next__\n",
      "    self.thread_condition.wait(timeout=0.100)\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\threading.py\", line 316, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\inspect.py\", line 1543, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\inspect.py\", line 1501, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\DDelgado\\anaconda3\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13868\\1084635565.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# Ajustar el modelo usando GridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\dask_ml\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m   1271\u001b[0m             \u001b[0mac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_completed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_results\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1272\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1273\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36mbatches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5966\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5967\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5968\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36mnext_batch\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   5938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5939\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5940\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\distributed\\client.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5894\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthread_condition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5895\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthread_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5896\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_and_raise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2076\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2077\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2078\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2077\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2078\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2079\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2080\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Definir las variables\n",
    "variables_a_excluir = [\n",
    "    'CCDD', 'DEPARTAMENTO', 'CCPP', 'PROVINCIA', 'CCDI', 'DISTRITO',\n",
    "    'CIUDAD', 'CONGLOMERADO', 'NSELV', 'VIVIENDA', 'THOGAR', 'NHOGAR',\n",
    "    'ESTRATO', 'VRESFIN', 'RESFIN', 'P15', 'P15_N', 'INF_200', 'P200_N',\n",
    "    'P609_COD', 'P611_COD', 'P625A_COD_DEPA', 'P625_COD_PROV', 'P625_COD_DIST',\n",
    "    'factorfinal', 'P602'\n",
    "]\n",
    "\n",
    "# Obtener la lista de todas las columnas\n",
    "todas_las_columnas = df.columns.tolist()\n",
    "\n",
    "# Determinar las covariables (X) excluyendo las especificadas\n",
    "columnas_covariables = [col for col in todas_las_columnas if col not in variables_a_excluir]\n",
    "\n",
    "# Definir predictores (X) y target (y)\n",
    "X = df[columnas_covariables]\n",
    "y = df['P602']  # Empleo\n",
    "\n",
    "\n",
    "# Configuración del cliente Dask\n",
    "Client(n_workers=4, threads_per_worker=2, memory_limit='4GB')\n",
    "\n",
    "# Particionamos los datos de antemano\n",
    "X = dd.from_pandas(X, npartitions=10)\n",
    "y = dd.from_pandas(y, npartitions=10)\n",
    "\n",
    "\n",
    "# División de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=4200, \n",
    "    shuffle=True  # Explicitly set shuffle\n",
    ")\n",
    "\n",
    "# Definir el modelo\n",
    "model = LogisticRegression()\n",
    "# Definir el grid para GridSearch\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = dml.GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Ajustar el modelo usando GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Selección del modelo óptimo\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluación en el conjunto de entrenamiento\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "train_accuracy = dmm.accuracy_score(y_train, y_train_pred)\n",
    "train_roc_auc = dmm.roc_auc_score(y_train, best_model.predict_proba(X_train)[:, 1])\n",
    "\n",
    "# Evaluación en el conjunto de prueba\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_accuracy = dmm.accuracy_score(y_test, y_test_pred)\n",
    "test_roc_auc = dmm.roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"Mejores parámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\nIndicadores de calidad de ajuste en entrenamiento:\")\n",
    "print(f\"Accuracy: {train_accuracy}\")\n",
    "print(f\"ROC AUC: {train_roc_auc}\")\n",
    "\n",
    "print(\"\\nIndicadores de calidad de ajuste en prueba:\")\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"ROC AUC: {test_roc_auc}\")\n",
    "\n",
    "# Reporte de clasificación para la muestra de prueba\n",
    "from dask_ml.metrics import classification_report\n",
    "print(\"\\nReporte de clasificación en prueba:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291b887",
   "metadata": {},
   "source": [
    "## Limitaciones y posibles extensiones\n",
    "1. El ajuste del modelo puede no ser óptimo si el grid de búsqueda es pequeño\n",
    "2. Los indicadores de calidad de ajuste dependen de la calidad de los datos.\n",
    "3. Se podría usar una mayor variedad de modelos y técnicas para comparación.\n",
    "4. La escalabilidad puede ser un problema con datasets extremadamente grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63c728",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d326a634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0825fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3f3ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
